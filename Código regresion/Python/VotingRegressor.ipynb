{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Código que  por cada columna de datos se intenta predecir su incremento en F dias usando los  incrementos que ha habido de otras columnas  desde hace P dias.  El conjunto de columnas que se usan para predecir es multiplo de p ya que se utilizan todos los pasados posibles de una columna.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Antes de ejecutar este código hay que  ejecutar el llamado limpiarCeros pues si en los datos hay algun cero, se prodicira un error  al llevar a cabo la division por 0 y dar de resultado infinito"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.7.0 (default, Jun 28 2018, 08:04:48) [MSC v.1912 64 bit (AMD64)]\n",
      "0.23.4\n",
      "0.21.0\n"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "import sys\n",
    "\n",
    "import numpy as np\n",
    "import math\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from sklearn import linear_model\n",
    "import sklearn\n",
    "print(sklearn.__version__)\n",
    "from sklearn.ensemble import VotingRegressor\n",
    "from math import sqrt\n",
    "\n",
    "d = pd.read_csv(\"rawVol.csv\",index_col=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pega(sentence):\n",
    "    sent_str = \"\"\n",
    "    for i in sentence:\n",
    "        sent_str += str(i)\n",
    "    return sent_str\n",
    "def cat(outfilename, line):\n",
    "    with open(outfilename, 'w') as outfile:\n",
    "            outfile.write(line)\n",
    "            outfile.close()\n",
    "def cat2(outfilename, line):\n",
    "    with open(outfilename,'a') as outfile:\n",
    "            outfile.write(line)\n",
    "            outfile.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "codigo =10\n",
    "prueba_numero =1\n",
    "\n",
    "f = 30\n",
    "p = 20\n",
    "\n",
    "prefix ='C:/Users/Celia/Desktop/4º/TFG/codigo/python/resultados'\n",
    "path = pega([prefix,'/errorNaive',codigo,prueba_numero,'.txt'])\n",
    "\n",
    "cat(path,pega([\"p: \",p,\" f: \",f,\"\\n\"]))\n",
    "errores =pega([prefix,'/rmse',codigo,prueba_numero,'.txt'])\n",
    "cat(errores,pega([\"Rmse mejores\",prueba_numero,\"\\n\"]))\n",
    "#archivo registro de pruebas\n",
    "n=pega([prefix,'/registro_pruebas',codigo,'.txt'])\n",
    "cat2(n,pega(['nº',prueba_numero ,' columna_predecir: BDIY_Index_Open ',\"p: \",p,\" f: \",f,\" columnas: \",len(d.columns),\" n: \",3,\"\\n\"]))\n",
    "\n",
    "\n",
    "max_col = 3\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "for col in list(d.columns.values):\n",
    "    #print(col)\n",
    "    if(col=='NKY_Index_Open'):# probar solo con euro\n",
    "        \n",
    "        present = d[(p):(len(d)-f)][col].reset_index()\n",
    "        future = d[(f+p):len(d)][col].reset_index()\n",
    "        # la etiqueta es el % de incremento en f días (saltando los p+1 primeros)\n",
    "\n",
    "        label1 = future.subtract(present, fill_value=0).reset_index()\n",
    "        label2 = (label1[col]/present[col]).reset_index()\n",
    "        label=label2.drop(label2.columns[[0]], axis='columns')\n",
    "\n",
    "\n",
    "        array = [0] * len(label)\n",
    "        zeros = pd.DataFrame(data=array)\n",
    "\n",
    "        a = label.values\n",
    "\n",
    "        rmse =sqrt(mean_squared_error(array, a))\n",
    "        cat2(path,pega([col,\" \", rmse,\"\\n\"]))\n",
    "        # hasta aqui columna label y error del naive\n",
    "        \n",
    "        rmse_up_to_now = 1\n",
    "        columns= []\n",
    "        column_names = []\n",
    "\n",
    "        n = 0\n",
    "        puntoFijo = False\n",
    "        cambios = 0\n",
    "        # miemtras que no se lleven el máximo de columnas y siga mejorando\n",
    "        while n < max_col and (not puntoFijo):\n",
    "            print(pega([\"n=\", n]))\n",
    "            ndf = columns\n",
    "            ini = 0\n",
    "            fin = len(d.columns)\n",
    "            fin =2\n",
    "            #recorre todas las columnas\n",
    "            for i in np.arange(ini, fin):\n",
    "                print(i)\n",
    "                #nombre de la columna\n",
    "                nombres = pega([list(d.columns.values)[i],1])\n",
    "                #si esa columna no ha sido cogida ya antes\n",
    "               \n",
    "                if not (nombres in column_names):\n",
    "                    pred = i\n",
    "                    s = np.arange(1, len(d)+1)# filas de la tabla\n",
    "                    vs = np.arange(0, p-1) # pasados a utilizar es ahasta p-1 porque no incluyepe la funcion arange\n",
    "                    name = list(d.columns.values)[pred]\n",
    "                    names = []\n",
    "                    #para la columna  i con la que quiero hacer la prediccion  en names estan los posibles pasados de esa columna a usar\n",
    "                    for v in vs:\n",
    "                        names.append(pega([name, (p-v),\"-\"]))\n",
    "                    df=pd.DataFrame(columns=names)\n",
    "                    # desde el dia p+1(cosas de indices) hasta el final menos futuro --> tabla\n",
    "                    for i in np.arange(p,len(d)-f):\n",
    "                        #para cada filla nrwo representa la fila actual\n",
    "                        nrow=[]\n",
    "                        #rellenar las columnas de (EuroPasado10, EuroPasado9, EuroPadaso8....)\n",
    "                        for v in vs:\n",
    "                            #calcular los incrementos que ha habido  en un marco temporal de 10 dias atras\n",
    "                            #d[ el dia a predeccir - (p-v= rango de 10 a 1) dias atras]\n",
    "                            nrow.append(((d.iloc[i-(p-v)+1][pred])-(d.iloc[i-(p-v)][pred]))/ (d.iloc[i-(p-v)][pred]))\n",
    "                        df.append(nrow)\n",
    "                        df = df.append(pd.Series(nrow, index=df.columns ), ignore_index=True)\n",
    "                     \n",
    "                    \n",
    "                    \n",
    "                    # se añade el mejor conjunto de columnas de la iteracion anterior de n si no es vacio\n",
    "                    if(len(columns)!=0):\n",
    "                        df=pd.concat([columns, df], axis=1, sort=False)\n",
    "                    \n",
    "                    # crear la matriz de datos con label\n",
    "                    datos = pd.concat([label, df], axis=1, sort=False)\n",
    "                    \n",
    "                   \n",
    "                    \n",
    "                    \n",
    "                    #-----------------EVALUACION---------------------------------------\n",
    "                   \n",
    "                        \n",
    "                            \n",
    "                   \n",
    "                    \n",
    "                    trainsize=1500 # tamaño de inicion del conjunto de entrenamiento\n",
    "                    s =np.arange(trainsize,len(datos)-f)\n",
    "                   \n",
    "                    predichos = []\n",
    "                    reales=[]\n",
    "                    for j in s:\n",
    "                        train = datos[1:j][:]\n",
    "                        reg1 = GradientBoostingRegressor(random_state=1, n_estimators=10)\n",
    "                        reg2 = RandomForestRegressor(random_state=1, n_estimators=10)\n",
    "                        reg3 = LinearRegression()\n",
    "                        ereg = VotingRegressor([('gb', reg1), ('rf', reg2), ('lr', reg3)])\n",
    "                        reg1.fit(train.iloc[:,1:],  train.iloc[:,0:1])\n",
    "                        reg2.fit(train.iloc[:,1:],  train.iloc[:,0:1])\n",
    "                        reg3.fit(train.iloc[:,1:],  train.iloc[:,0:1])\n",
    "                        ereg.fit(train.iloc[:,1:], train.iloc[:,0:1])\n",
    "                        \n",
    "                        #vr.fit(train.iloc[:,1:], train.iloc[:,0:1])\n",
    "                        \n",
    "                        test=datos.iloc[[j+f],1:]\n",
    "                        Y_pred = ereg.predict(test)\n",
    "                        real =datos.iloc[[j+f],0:1]\n",
    "                        \n",
    "                        valor_p =Y_pred[0]\n",
    "                        valor_r=real.iloc[0,0]\n",
    "                        print(valor_p,valor_r)\n",
    "                        predichos.append(valor_p)\n",
    "                        reales.append(valor_r)\n",
    "                    \n",
    "                    \n",
    "                    rmse =sqrt(mean_squared_error(reales, predichos))\n",
    "                    cambios +=1\n",
    "                    \n",
    "                    #si mejora\n",
    "                    if(not(np.isnan(rmse)) and rmse<rmse_up_to_now):\n",
    "                        rmse_up_to_now=rmse\n",
    "                        ndf= df\n",
    "                        cat2(errores,pega([col, \" con \", name,\" iteracion\", n,\" \", rmse_up_to_now,\"\\n\"]))\n",
    "                \n",
    "                        \n",
    "             \n",
    "            print(pega([\"mejores columnas iteracion: \",n]))\n",
    "            print(ndf.columns.values)\n",
    "                  \n",
    "            # aqui termina la busqueda de la combinacion de pasasdos para las columnas i para predecir la columna col         \n",
    "            if(cambios>0 or len(columns==0) or not (columns.columns.values ==ndf.columns.values) ) :\n",
    "               \n",
    "                columns = ndf\n",
    "              \n",
    "                columns_names = columns.columns.values\n",
    "                \n",
    "                print(\"cambio columnas\")\n",
    "                print(column_names)\n",
    "                n+=1\n",
    "            else:\n",
    "                print(\"vuelta sin cabios\")\n",
    "                puntoFijo = True\n",
    "                    \n",
    "        print(\"Acabado\")\n",
    "        cat2(errores,pega([col, \" acabado \", ndf.columns.values, rmse_up_to_now,\"\\n\"]))\n",
    "        print(rmse_up_to_now)\n",
    "        print(ndf.columns.values)\n",
    "    \n",
    "                    \n",
    "               \n",
    "                    \n",
    "               \n",
    "                    \n",
    "                   \n",
    "                    \n",
    "                    \n",
    "                    \n",
    "                    \n",
    "          \n",
    "\n",
    "   \n",
    "\n",
    "    \n",
    "    \n",
    "     \n",
    "\n",
    "\n",
    "    \n",
    "    \n",
    "   \n",
    "    \n",
    "    \n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(d.columns.values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "print(__doc__)\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn import datasets\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.ensemble import VotingRegressor\n",
    "\n",
    "# Loading some example data\n",
    "boston = datasets.load_boston()\n",
    "X = boston.data\n",
    "y = boston.target\n",
    "\n",
    "# Training classifiers\n",
    "reg1 = GradientBoostingRegressor(random_state=1, n_estimators=10)\n",
    "reg2 = RandomForestRegressor(random_state=1, n_estimators=10)\n",
    "reg3 = LinearRegression()\n",
    "ereg = VotingRegressor([('gb', reg1), ('rf', reg2), ('lr', reg3)])\n",
    "reg1.fit(X, y)\n",
    "reg2.fit(X, y)\n",
    "reg3.fit(X, y)\n",
    "ereg.fit(X, y)\n",
    "\n",
    "xt = X[19:20]\n",
    "print(ereg.predict(xt))\n",
    "plt.figure()\n",
    "plt.plot(reg1.predict(xt), 'gd', label='GradientBoostingRegressor')\n",
    "plt.plot(reg2.predict(xt), 'b^', label='RandomForestRegressor')\n",
    "plt.plot(reg3.predict(xt), 'ys', label='LinearRegression')\n",
    "plt.plot(ereg.predict(xt), 'r*', label='VotingRegressor')\n",
    "plt.tick_params(axis='x', which='both', bottom=False, top=False,\n",
    "                labelbottom=False)\n",
    "plt.ylabel('predicted')\n",
    "plt.xlabel('training samples')\n",
    "plt.legend(loc=\"best\")\n",
    "plt.title('Comparison of individual predictions with averaged')\n",
    "print(plt.show())\n",
    "   \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.iloc[4][5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
